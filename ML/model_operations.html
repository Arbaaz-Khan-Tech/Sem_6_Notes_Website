<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Model Operations - ML Guide</title>
    <link rel="stylesheet" href="model_operations.css">
    <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@400;500&family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/latex.js@0.12.1/dist/latex.min.js"></script>
</head>
<body>
    <nav class="navbar">
        <div class="nav-content">
            <a href="ML_Questions.html" class="nav-link">
                <i class="fas fa-home"></i> Home
            </a>
            <button id="themeToggle" class="theme-toggle">
                <i class="fas fa-moon"></i>
            </button>
        </div>
    </nav>

    <main>
        <section class="hero">
            <h1>Model Operations</h1>
            <p>Understanding Model Evaluation, Performance Metrics, and the Confusion Matrix</p>
        </section>

        <section class="core-concepts">
            <h2>Core Concepts (V.V.IMP)</h2>
            
            <div class="concept-card overfitting-underfitting">
                <h3>Overfitting vs. Underfitting</h3>
                <p>Understanding the balance between model complexity and generalization.</p>
                
                <div class="comparison-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Aspect</th>
                                <th>Overfitting</th>
                                <th>Underfitting</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Definition</td>
                                <td><span class="highlight-red">Model memorizes noise (high variance)</span></td>
                                <td><span class="highlight-blue">Model is too simple (high bias)</span></td>
                            </tr>
                            <tr>
                                <td>Training Error</td>
                                <td><span class="highlight-red">Very low (near 0%)</span></td>
                                <td><span class="highlight-blue">High</span></td>
                            </tr>
                            <tr>
                                <td>Test Error</td>
                                <td><span class="highlight-red">Much higher than training error</span></td>
                                <td><span class="highlight-blue">High (similar to training)</span></td>
                            </tr>
                            <tr>
                                <td>Visual Cue</td>
                                <td><span class="highlight-red">Jagged curve fitting all points (üå™Ô∏è Chaos)</span></td>
                                <td><span class="highlight-blue">Straight line missing patterns (üìâ Too rigid)</span></td>
                            </tr>
                            <tr>
                                <td>Fix</td>
                                <td><span class="highlight-red">Regularization, dropout, more data</span></td>
                                <td><span class="highlight-blue">Add features, increase model complexity</span></td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="example-section">
                    <h4>Example: Polynomial Regression</h4>
                    <p>Let's see how different polynomial degrees affect model fitting:</p>
                    
                    <div class="step-by-step">
                        <h5>Underfitting (Degree = 1)</h5>
                        <p>\[y = w_0 + w_1x\]</p>
                        <p><span class="highlight-blue">Too simple to capture patterns</span></p>
                        
                        <h5>Good Fit (Degree = 3)</h5>
                        <p>\[y = w_0 + w_1x + w_2x^2 + w_3x^3\]</p>
                        <p><span class="highlight-green">Balanced complexity</span></p>
                        
                        <h5>Overfitting (Degree = 10)</h5>
                        <p>\[y = w_0 + w_1x + ... + w_{10}x^{10}\]</p>
                        <p><span class="highlight-red">Fits noise in the data</span></p>
                    </div>
                </div>

                <div class="memory-aid">
                    <h4>Shortcut to Remember:</h4>
                    <p>"<span class="highlight-yellow">Overfit = Memorizing the textbook (fails surprise tests). Underfit = Guessing randomly (fails everything).</span>"</p>
                </div>
            </div>

            <div class="concept-card performance-metrics">
                <h3>Performance Metrics</h3>
                <p>Understanding how to evaluate model performance.</p>

                <div class="metrics-grid">
                    <div class="metric-card">
                        <h4>Accuracy</h4>
                        <p class="formula">\[\frac{TP + TN}{Total}\]</p>
                        <p><span class="highlight-blue">Use when classes are balanced</span></p>
                    </div>
                    
                    <div class="metric-card">
                        <h4>Precision</h4>
                        <p class="formula">\[\frac{TP}{TP + FP}\]</p>
                        <p><span class="highlight-green">Use when false positives are costly</span></p>
                    </div>
                    
                    <div class="metric-card">
                        <h4>Recall</h4>
                        <p class="formula">\[\frac{TP}{TP + FN}\]</p>
                        <p><span class="highlight-red">Use when false negatives are costly</span></p>
                    </div>
                    
                    <div class="metric-card">
                        <h4>F1-Score</h4>
                        <p class="formula">\[2 \times \frac{Precision \times Recall}{Precision + Recall}\]</p>
                        <p><span class="highlight-purple">Use for imbalanced data</span></p>
                    </div>
                </div>

                <div class="confusion-matrix">
                    <h4>Confusion Matrix</h4>
                    <div class="matrix-table">
                        <table>
                            <thead>
                                <tr>
                                    <th></th>
                                    <th>Predicted: Yes</th>
                                    <th>Predicted: No</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Actual: Yes</td>
                                    <td><span class="highlight-green">True Positive (TP) ‚úÖ</span></td>
                                    <td><span class="highlight-red">False Negative (FN) ‚ùå</span></td>
                                </tr>
                                <tr>
                                    <td>Actual: No</td>
                                    <td><span class="highlight-red">False Positive (FP) ‚ùå</span></td>
                                    <td><span class="highlight-green">True Negative (TN) ‚úÖ</span></td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>

                <div class="memory-aid">
                    <h4>Shortcut to Remember:</h4>
                    <p>"<span class="highlight-yellow">Precision = Don't cry wolf (avoid FP). Recall = Catch all wolves (avoid FN).</span>"</p>
                </div>
            </div>
        </section>

        <section class="detailed-explanation">
            <h2>Detailed Explanation</h2>
            
            <div class="explanation-card">
                <h3>Overfitting vs. Underfitting in Detail</h3>
                <div class="explanation-content">
                    <p><span class="highlight-blue">Model Evaluation</span> is crucial for understanding how well your model performs. Here's a deeper look at overfitting and underfitting:</p>
                    
                    <h4>Overfitting (High Variance)</h4>
                    <ul>
                        <li><span class="highlight-red">Symptoms</span>: Model performs well on training data but poorly on new data</li>
                        <li><span class="highlight-red">Causes</span>: Too complex model, insufficient data, noise in data</li>
                        <li><span class="highlight-red">Solutions</span>: Regularization, dropout, data augmentation, early stopping</li>
                    </ul>

                    <h4>Underfitting (High Bias)</h4>
                    <ul>
                        <li><span class="highlight-blue">Symptoms</span>: Model performs poorly on both training and test data</li>
                        <li><span class="highlight-blue">Causes</span>: Too simple model, insufficient features</li>
                        <li><span class="highlight-blue">Solutions</span>: Add more features, increase model complexity, reduce regularization</li>
                    </ul>
                </div>
            </div>

            <div class="explanation-card">
                <h3>Performance Metrics in Detail</h3>
                <div class="explanation-content">
                    <p><span class="highlight-green">Performance Metrics</span> help us quantify how well our model is performing. Here's a detailed explanation of each metric:</p>
                    
                    <h4>Accuracy</h4>
                    <ul>
                        <li><span class="highlight-blue">Definition</span>: Proportion of correct predictions</li>
                        <li><span class="highlight-blue">Use Case</span>: When classes are balanced</li>
                        <li><span class="highlight-blue">Limitation</span>: Can be misleading with imbalanced data</li>
                    </ul>

                    <h4>Precision and Recall</h4>
                    <ul>
                        <li><span class="highlight-green">Precision</span>: Focuses on the accuracy of positive predictions</li>
                        <li><span class="highlight-red">Recall</span>: Focuses on the ability to find all positive cases</li>
                        <li><span class="highlight-purple">Trade-off</span>: Increasing one often decreases the other</li>
                    </ul>

                    <h4>F1-Score</h4>
                    <ul>
                        <li><span class="highlight-yellow">Definition</span>: Harmonic mean of precision and recall</li>
                        <li><span class="highlight-yellow">Use Case</span>: When you need a balanced measure</li>
                        <li><span class="highlight-yellow">Advantage</span>: Works well with imbalanced data</li>
                    </ul>
                </div>
            </div>
        </section>

        <section class="memory-aids">
            <h2>Memory Aids & Quick References</h2>
            
            <div class="memory-content">
                <div class="memory-card">
                    <h3>Overfitting vs. Underfitting Memory Tricks</h3>
                    <ul>
                        <li><span class="highlight-red">Overfitting</span> = <span class="highlight-yellow">O</span>verly complex (like memorizing a textbook)</li>
                        <li><span class="highlight-blue">Underfitting</span> = <span class="highlight-yellow">U</span>nderwhelming (like guessing randomly)</li>
                        <li><span class="highlight-green">Good Fit</span> = <span class="highlight-yellow">G</span>oldilocks (just right)</li>
                    </ul>
                    <p class="mnemonic">Remember: "<span class="highlight-purple">Overfit = Memorizing the textbook (fails surprise tests). Underfit = Guessing randomly (fails everything).</span>"</p>
                </div>

                <div class="memory-card">
                    <h3>Performance Metrics Memory Tricks</h3>
                    <ul>
                        <li><span class="highlight-blue">Accuracy</span> = <span class="highlight-yellow">A</span>ll correct predictions</li>
                        <li><span class="highlight-green">Precision</span> = <span class="highlight-yellow">P</span>recise positive predictions</li>
                        <li><span class="highlight-red">Recall</span> = <span class="highlight-yellow">R</span>ecover all positive cases</li>
                        <li><span class="highlight-purple">F1-Score</span> = <span class="highlight-yellow">F</span>ind balance between precision and recall</li>
                    </ul>
                    <p class="mnemonic">Remember: "<span class="highlight-purple">Precision = Don't cry wolf (avoid FP). Recall = Catch all wolves (avoid FN).</span>"</p>
                </div>
            </div>
        </section>

        <section class="points-to-remember">
            <h2>Points to Remember (V.V.IMP)</h2>
            
            <div class="points-grid">
                <div class="point-card">
                    <i class="fas fa-exclamation-circle"></i>
                    <h3>Overfitting</h3>
                    <p>High training accuracy, low test accuracy</p>
                </div>
                
                <div class="point-card">
                    <i class="fas fa-exclamation-circle"></i>
                    <h3>Underfitting</h3>
                    <p>Low training accuracy, low test accuracy</p>
                </div>
                
                <div class="point-card">
                    <i class="fas fa-exclamation-circle"></i>
                    <h3>Precision vs. Recall</h3>
                    <p>Trade-off between false positives and false negatives</p>
                </div>
                
                <div class="point-card">
                    <i class="fas fa-exclamation-circle"></i>
                    <h3>F1-Score</h3>
                    <p>Balanced measure for imbalanced data</p>
                </div>
            </div>
        </section>
    </main>

    <script src="model_operations.js"></script>
</body>
</html> 